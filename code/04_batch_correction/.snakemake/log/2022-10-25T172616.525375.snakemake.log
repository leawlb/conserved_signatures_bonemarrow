Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cluster nodes: 4
Job stats:
job                    count    min threads    max threads
-------------------  -------  -------------  -------------
all                        1              1              1
make_summary_report        1              1              1
total                      2              1              1

Select jobs to execute...

[Tue Oct 25 17:26:19 2022]
rule make_summary_report:
    input: /omics/odcf/analysis/OE0538_projects/DO-0008/data/sce_objects/06_mrge, /omics/odcf/analysis/OE0538_projects/DO-0008/data/sce_objects/07_rnrm, /omics/odcf/analysis/OE0538_projects/DO-0008/data/sce_objects/08_mnncorrect
    output: /omics/odcf/analysis/OE0538_projects/DO-0008/data/sce_objects/reports/integration/integration_summary.html
    jobid: 0
    resources: tmpdir=/tmp

Submitted job 0 with external jobid 'Job <16938096> is submitted to queue <verylong>.'.
Terminating processes on user request, this might take some time.
Will exit after finishing currently running jobs.
Complete log: /home/l012t/repositories/Interspecies_BM_phd/code/03_integration/.snakemake/log/2022-10-25T172616.525375.snakemake.log
